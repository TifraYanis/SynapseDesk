# ğŸ§  SynapseDesk â€” Copilote RAG local (Ollama + Mistral)

![Python](https://img.shields.io/badge/Python-3.11%2B-blue.svg)
![FastAPI](https://img.shields.io/badge/FastAPI-0.115-green.svg)
![Streamlit](https://img.shields.io/badge/Streamlit-1.38.0-FF4B4B.svg)
![Ollama](https://img.shields.io/badge/Ollama-Mistral_7B-lightgrey.svg)
![FAISS](https://img.shields.io/badge/FAISS-BM25%20Hybrid-orange.svg)
![License](https://img.shields.io/badge/License-MIT-blue.svg)

---

## ğŸš€ PrÃ©sentation du projet

**SynapseDesk** est un copilote dâ€™entreprise local conÃ§u pour aider les Ã©quipes **Data, IT, RH, DevOps ou mÃ©tiers**.  
Il connecte vos **donnÃ©es internes (docs, logs, fiches, tickets)** Ã  un **LLM local (Mistral 7B via Ollama)** pour fournir :
- des **diagnostics techniques** (jobs Spark, configurations, logs),
- des **explications** claires sur des politiques ou procÃ©dures,
- des **rÃ©ponses sourcÃ©es et contextualisÃ©es**,
- et des **analyses actionnables**.

ğŸ¯ **Objectif :** un assistant robuste, privÃ© et directement exploitable en entreprise.

---
## ğŸ¥ DÃ©monstration visuelle

<p align="center">
  <img src="assets/pagedefilante.gif" alt="DÃ©monstration du copilote RAG SynapseDesk" width="850">
</p>

---
## ğŸ§© Architecture

```
Utilisateur â†’ Streamlit UI â†’ FastAPI API â†’ Retriever hybride (FAISS + BM25)
                                  â†³ Cross-Encoder (re-ranking)
                                  â†³ Mistral (Ollama) â†’ RÃ©ponse structurÃ©e
```

### ğŸ”¹ Ã‰tapes principales
1. **Ingestion & Normalisation** : extraction texte depuis `api/data/` (md, txt, html, docx, json, code).  
2. **Indexation hybride** : gÃ©nÃ©ration dâ€™embeddings (`intfloat/multilingual-e5-base`) + BM25 lexical.  
3. **Retrieval & Fusion** : recherche sÃ©mantique et lexicale, fusionnÃ©e par score.  
4. **Re-ranking** : reclassement prÃ©cis via CrossEncoder.  
5. **SynthÃ¨se** : Mistral (via Ollama) produit une rÃ©ponse claire, justifiÃ©e et citÃ©e.  
6. **Fallback automatique** : si `max_score < 0.01`, bascule en **chat libre** sans contexte.

---

## âš™ï¸ Stack technique

| Composant | Description |
|------------|-------------|
| ğŸ§  **LLM local** | Mistral 7B via Ollama (`localhost:11434`) |
| ğŸš€ **Backend API** | FastAPI (Python 3.11) |
| ğŸ” **Retrieval** | FAISS (embeddings denses) + BM25 (lexical) |
| ğŸª„ **Re-ranking** | CrossEncoder (`ms-marco-MiniLM-L-6-v2`) |
| ğŸ’¬ **Frontend** | Streamlit multipage (Copilot / PrÃ©sentation / Tests) |
| ğŸ—‚ï¸ **Indexation** | `scripts/build_hybrid_index.py` |
| ğŸ“š **Ingestion** | `api/ingest_data.py` |
| ğŸ§± **DonnÃ©es simulÃ©es** | Logs Spark, fiches internes, FAQ, RH, tickets |

---

## ğŸ§  Logique adaptative

Le systÃ¨me Ã©value la pertinence des passages trouvÃ©s :
- Si le **score maximal** â‰¥ `0.01` â†’ **RAG activÃ©** (rÃ©ponse sourcÃ©e Ã  partir des donnÃ©es internes)
- Si le **score maximal** < `0.01` â†’ **chat libre** (rÃ©ponse gÃ©nÃ©rative du LLM)

> âš–ï¸ Cette logique Ã©vite les â€œhallucinationsâ€ et garantit que le modÃ¨le ne sâ€™appuie que sur des sources fiables.

---

## ğŸ§‘â€ğŸ’» Installation et exÃ©cution

### 1ï¸âƒ£ Cloner le dÃ©pÃ´t
```bash
git clone https://github.com/TifraYanis/synapsedesk.git
cd synapsedesk
```

### 2ï¸âƒ£ CrÃ©er lâ€™environnement et installer les dÃ©pendances
```bash
python -m venv .venv
.venv\Scripts\activate   # Windows
pip install -r requirements.txt
```

### 3ï¸âƒ£ GÃ©nÃ©rer les donnÃ©es et index
```bash
make generate-data    # crÃ©e des donnÃ©es internes simulÃ©es
make ingest           # convertit les fichiers en corpus.jsonl
make build-index      # crÃ©e les index FAISS + BM25
```

### 4ï¸âƒ£ Lancer Ollama et tÃ©lÃ©charger Mistral
```bash
ollama pull mistral
ollama serve
```

### 5ï¸âƒ£ DÃ©marrer lâ€™API et le front
```bash
make api
make streamlit
```

â¡ï¸ Application disponible sur : [http://localhost:8501](http://localhost:8501)

---

## ğŸ–¥ï¸ Interface Streamlit

**3 onglets principaux :**
1. ğŸ’¬ **Copilot** â€“ Chat multi-conversation (RAG + citations internes)
2. ğŸ“˜ **PrÃ©sentation** â€“ Architecture, pipeline, choix techniques dÃ©taillÃ©s
3. ğŸ§ª **Tests** â€“ ScÃ©narios et cas de validation automatiques

---

## ğŸ¨ Design

- Interface sombre Ã©lÃ©gante (`#0E1117 / #1E1E2E / #00FFB3`)
- Effet lumineux sur les titres et transitions fluides
- Citations pliables avec affichage des scores
- Responsive et Ã©purÃ©

---

## ğŸ§© Structure du projet

```
SYNAPSEDESK/
â”œâ”€â”€ api/
â”‚   â”œâ”€â”€ ingest_data.py       # Ingestion & nettoyage des fichiers
â”‚   â”œâ”€â”€ retriever.py         # FAISS + BM25 + re-ranking
â”‚   â”œâ”€â”€ llm_manager.py       # Interface Ollama
â”‚   â””â”€â”€ main.py              # FastAPI backend
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ build_hybrid_index.py
â”‚   â””â”€â”€ generate_data.py
â”œâ”€â”€ indices/                 # Index FAISS + BM25 gÃ©nÃ©rÃ©s
â”œâ”€â”€ streamlit_app/
â”‚   â”œâ”€â”€ app.py
â”‚   â””â”€â”€ pages/
â”‚       â”œâ”€â”€ 1_Copilot.py
â”‚       â”œâ”€â”€ 2_Presentation.py
â”‚       â””â”€â”€ 3_Tests.py
â”œâ”€â”€ configs/settings.yaml
â”œâ”€â”€ Makefile
â””â”€â”€ requirements.txt
```

---

## ğŸ“ˆ Exemple de rÃ©ponse

**Question :** â€œPourquoi mon job `bronze_to_silver` est lent ?â€

```
RÃ©sumÃ© : Probable saturation mÃ©moire sur le stage 3.
Analyse : dÃ©sÃ©quilibre de partitions et jointures non broadcastÃ©es.
Actions : vÃ©rifier spark.sql.shuffle.partitions, filtrer les tables amont, utiliser broadcast join.
Sources : logs/log_0042.json, docs/Troubleshooting_Spark.md
```

---

## ğŸ”® AmÃ©liorations prÃ©vues

- ğŸ§¾ Support PDF + OCR (Tesseract)
- ğŸ” Cache Redis pour accÃ©lÃ©rer le retrieval
- ğŸ“Š Dashboard dâ€™analyse et monitoring
- ğŸ§© Historique multi-utilisateurs
- ğŸ›¡ï¸ Guardrails (dÃ©tection PII, sensibilitÃ© des donnÃ©es)

---

## ğŸ‘¤ Auteur

**Tifra Yanis**  
ğŸ“ Data / AI Engineer â€” France  
ğŸ”— [LinkedIn](https://www.linkedin.com/in/yanis-tifra-969134204/)  
ğŸ’» [GitHub](https://github.com/TifraYanis)

---

## ğŸ“œ Licence

Sous licence **MIT**, libre de rÃ©utilisation et dâ€™adaptation, avec attribution Ã  lâ€™auteur original.

```
MIT License Â© 2025 Tifra Yanis
```

---

## â­ Support & feedback

Si le projet tâ€™a aidÃ© :
- â­ Laisse une Ã©toile sur GitHub  
- ğŸ” Forke et adapte Ã  ton environnement  
- ğŸ§  Mentionne-le sur ton portfolio ou LinkedIn (`#RAG #LLM #FastAPI #Streamlit #Mistral`)  
